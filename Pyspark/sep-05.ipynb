{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nl27UJX0UzXO","outputId":"b6dbd467-f1ce-4c72-d6a9-6f812f3c7932"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyspark\n","  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=e296a12ffbd29afaaa3f79990ec615a3e87e2cd72aa25471b7f11d0e552924bd\n","  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.2\n"]}],"source":["! pip install pyspark"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZsWqklpdVIOl","executionInfo":{"status":"ok","timestamp":1725508818172,"user_tz":-330,"elapsed":12390,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}}},"outputs":[],"source":["from pyspark.sql import SparkSession\n","\n","\n","# Initialize a Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"Advanced DataFrame Operations - Different Dataset\") \\\n","    .getOrCreate()"]},{"cell_type":"code","source":["csv_file_path = \"/content/sample_data/people.csv\"\n","\n","#Now you can read it with pyspark\n","df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n","df_csv.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qbiO_qIsWpAZ","executionInfo":{"status":"ok","timestamp":1725509597044,"user_tz":-330,"elapsed":10749,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"7bce733f-fd11-4bfb-b208-3db2ab466057"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+----+-------+\n","|Name| Age| Gender|\n","+----+----+-------+\n","|John|  28|   Male|\n","|Jane|  32| Female|\n","+----+----+-------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n","\n","# Define the schema for the JSON file\n","schema = StructType([\n","    StructField(\"name\", StringType(), True),\n","    StructField(\"age\", IntegerType(), True),\n","    StructField(\"gender\", StringType(), True),\n","    StructField(\"address\", StructType([\n","        StructField(\"street\", StringType(), True),\n","        StructField(\"city\", StringType(), True)\n","    ]), True)\n","])\n","\n","\n","# load the complex json file with the correct path\n","json_file_path = \"/content/sample_data/sample.json\"\n","\n","df_json_complex = spark.read.schema(schema).json(json_file_path)\n","\n","with open(json_file_path, \"r\") as f:\n","  data = f.read()\n","  print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3hRoJnDacpBP","executionInfo":{"status":"ok","timestamp":1725511064187,"user_tz":-330,"elapsed":435,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"9c457722-d0bb-4bc5-e5b7-59cf5ff5c66f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[\n","  {\n","    \"name\": \"John\",\n","    \"age\": 28,\n","    \"gender\": \"Male\",\n","    \"address\": {\n","      \"street\": \"123 Main St\",\n","      \"city\": \"New York\"\n","    }\n","  },\n","  {\n","    \"name\": \"Jane\",\n","    \"age\": 32,\n","    \"gender\": \"Female\",\n","    \"address\": {\n","      \"street\": \"456 Elm St\",\n","      \"city\": \"San Francisco\"\n","    }\n","  }\n","]\n"]}]},{"cell_type":"markdown","source":["temp view and global temp view"],"metadata":{"id":"_XUvtFzikdcQ"}},{"cell_type":"code","source":["import pandas as pd\n","data = {\n","    \"name\": [\"John\", \"Jane\", \"Mike\", \"Emily\"],\n","    \"age\": [28, 32, 45, 23],\n","    \"gender\": [\"Male\", \"Female\", \"Male\", \"Female\"],\n","    \"city\": [\"New York\", \"San Francisco\", \"Los Angeles\", \"Chicago\"]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","csv_file_path = \"/content/sample_people.csv\"\n","df.to_csv(csv_file_path, index=False)\n","\n","print(\"csv file is created \")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"naq7rpeThiEo","executionInfo":{"status":"ok","timestamp":1725512824095,"user_tz":-330,"elapsed":420,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"58b8f9c1-8a68-4549-d164-fb4a2b5a4512"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["csv file is created \n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"CreateViewExample\").getOrCreate()\n","df_people = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(csv_file_path)\n","df_people.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Owmc54LMkwy1","executionInfo":{"status":"ok","timestamp":1725512767147,"user_tz":-330,"elapsed":4168,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"624e004d-471e-48ec-bdb5-cb2f140a3005"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+------+-------------+\n","| name|age|gender|         city|\n","+-----+---+------+-------------+\n","| John| 28|  Male|     New York|\n","| Jane| 32|Female|San Francisco|\n","| Mike| 45|  Male|  Los Angeles|\n","|Emily| 23|Female|      Chicago|\n","+-----+---+------+-------------+\n","\n"]}]},{"cell_type":"markdown","source":["create a temperory view"],"metadata":{"id":"hABhZm-MlRtW"}},{"cell_type":"code","source":["df_people.createOrReplaceTempView(\"people_temp_view\")\n"],"metadata":{"id":"8tOlAXDflEcV","executionInfo":{"status":"ok","timestamp":1725512956538,"user_tz":-330,"elapsed":426,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#run an sql query on the view\n","result_temp_view = spark.sql(\"SELECT name, age, gender, city FROM people_temp_view WHERE age > 30\")\n","result_temp_view.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4uUj4aVlVkD","executionInfo":{"status":"ok","timestamp":1725512960773,"user_tz":-330,"elapsed":1250,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"f96a5cd1-ed3b-4602-deb5-b1392dd3e0e0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+---+------+-------------+\n","|name|age|gender|         city|\n","+----+---+------+-------------+\n","|Jane| 32|Female|San Francisco|\n","|Mike| 45|  Male|  Los Angeles|\n","+----+---+------+-------------+\n","\n"]}]},{"cell_type":"markdown","source":["create a global temporary view"],"metadata":{"id":"cgz8gpaxllso"}},{"cell_type":"code","source":["df_people.createOrReplaceGlobalTempView(\"people_global_view\")\n","result_global_view = spark.sql(\"SELECT name, age, city FROM global_temp.people_global_view WHERE age < 30\")\n","result_global_view.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JICbBWtlsRr","executionInfo":{"status":"ok","timestamp":1725513021051,"user_tz":-330,"elapsed":1465,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"dd31eb10-ea81-46d5-aad4-a2593f2d6194"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+--------+\n","| name|age|    city|\n","+-----+---+--------+\n","| John| 28|New York|\n","|Emily| 23| Chicago|\n","+-----+---+--------+\n","\n"]}]},{"cell_type":"markdown","source":["List All Temporary Views and Tables: This lists all the temporary views and tables within the Spark session:"],"metadata":{"id":"HSqTyBHNl3rZ"}},{"cell_type":"code","source":["spark.catalog.listTables()\n","\n","spark.catalog.dropTempView(\"people_temp_view\")\n","spark.catalog.dropGlobalTempView(\"people_global_view\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCGYfRnjl40C","executionInfo":{"status":"ok","timestamp":1725513078230,"user_tz":-330,"elapsed":1200,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"fadba714-4293-4b1a-da24-417d762062ca"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# Create a new database in Spark SQL\n","spark.sql(\"CREATE DATABASE IF NOT EXISTS my_database\")\n","\n","# Use the created database\n","spark.sql(\"USE my_database\")\n","\n","# Verify that the database is being used\n","spark.sql(\"SHOW DATABASES\").show()\n","\n","for data base"],"metadata":{"id":"wYpHxUSc7Hr7"}}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCOUH/5DdvSXn5wecGwmqZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}