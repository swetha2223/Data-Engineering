{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPJ5o8O+ApSghhea2jIduMN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t01m9EdH8ime","executionInfo":{"status":"ok","timestamp":1725519065006,"user_tz":-330,"elapsed":52445,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"cec9e70f-51ce-44c9-ce0e-7ee694c4be61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=f055cc081151992c624e2a18cd718004251a0aab0ee1d16a414522c86bb4f363\n","  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.2\n"]}],"source":["! pip install pyspark"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","\n","# Initialize a Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"Advanced DataFrame Operations - Different Dataset\") \\\n","    .getOrCreate()"],"metadata":{"id":"NWsctBtN8tTE","executionInfo":{"status":"ok","timestamp":1725519074166,"user_tz":-330,"elapsed":9164,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Extract"],"metadata":{"id":"G0Bsjka698-4"}},{"cell_type":"code","source":["csv_file_path = \"/content/sample_data/employee.csv\"\n","\n","#Now you can read it with pyspark\n","df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n","df_csv.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33zWyh8o89n_","executionInfo":{"status":"ok","timestamp":1725520804704,"user_tz":-330,"elapsed":1264,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"332ecb76-1ada-40c4-8061-bf88a085ba7d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+------+------+\n","| name|age|gender|salary|\n","+-----+---+------+------+\n","| John| 28|  Male| 60000|\n","| Jane| 32|Female| 72000|\n","| Mike| 45|  Male| 84000|\n","|Emily| 23|Female| 52000|\n","| Alex| 36|  Male| 67000|\n","+-----+---+------+------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"EmployeeSalaryETL\").getOrCreate()\n","df_employee = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(csv_file_path)\n","df_employee.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6tYQ6mDAzNI","executionInfo":{"status":"ok","timestamp":1725521071399,"user_tz":-330,"elapsed":1312,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"eaabc308-b582-4495-c020-6dd972e346fd"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+------+------+\n","| name|age|gender|salary|\n","+-----+---+------+------+\n","| John| 28|  Male| 60000|\n","| Jane| 32|Female| 72000|\n","| Mike| 45|  Male| 84000|\n","|Emily| 23|Female| 52000|\n","| Alex| 36|  Male| 67000|\n","+-----+---+------+------+\n","\n"]}]},{"cell_type":"markdown","source":["Transform"],"metadata":{"id":"BODyBUsj9___"}},{"cell_type":"code","source":["# Transform: Filter employees aged 30 and above\n","from pyspark.sql.functions import col\n","\n","df_filtered = df_employee.filter(col(\"age\") >= 30)\n","df_filtered.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jlQNH_bL-jSq","executionInfo":{"status":"ok","timestamp":1725521182818,"user_tz":-330,"elapsed":521,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"707c46ab-9cdb-4cb4-90bb-322cc3f88fa6"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+---+------+------+\n","|name|age|gender|salary|\n","+----+---+------+------+\n","|Jane| 32|Female| 72000|\n","|Mike| 45|  Male| 84000|\n","|Alex| 36|  Male| 67000|\n","+----+---+------+------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql.functions import col,round\n","df_transformed = df_employee.withColumn(\"salary_with_bonus\", round(col(\"salary\") * 1.10, 2))\n","\n","# Show transformed data\n","df_transformed.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cIiDOmQBmDe","executionInfo":{"status":"ok","timestamp":1725521229289,"user_tz":-330,"elapsed":436,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"3e7a140d-ce04-458e-846d-5f158b854c00"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+------+------+-----------------+\n","| name|age|gender|salary|salary_with_bonus|\n","+-----+---+------+------+-----------------+\n","| John| 28|  Male| 60000|          66000.0|\n","| Jane| 32|Female| 72000|          79200.0|\n","| Mike| 45|  Male| 84000|          92400.0|\n","|Emily| 23|Female| 52000|          57200.0|\n","| Alex| 36|  Male| 67000|          73700.0|\n","+-----+---+------+------+-----------------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql.functions import round,avg\n","df_avg_salary_by_gender = df_employee.groupBy(\"gender\").agg(round(avg(\"salary\"), 2).alias(\"avg_salary\"))\n","\n","# Show the result (average salary by gender)\n","df_avg_salary_by_gender.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZuFOhAxEUQC","executionInfo":{"status":"ok","timestamp":1725521253616,"user_tz":-330,"elapsed":1996,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"556b0f3f-406d-4f29-af6d-4511cc513fa0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+----------+\n","|gender|avg_salary|\n","+------+----------+\n","|Female|   62000.0|\n","|  Male|  70333.33|\n","+------+----------+\n","\n"]}]},{"cell_type":"markdown","source":["Load"],"metadata":{"id":"Pe5WzK8JFR_U"}},{"cell_type":"code","source":["# Path to save the Parquet file\n","parquet_output_path =\"/content/sample_data/employee_data_with_bonus.parquet\"\n","\n","# Save the transformed DataFrame to a Parquet file\n","df_transformed.write.parquet(parquet_output_path, mode=\"overwrite\")\n","\n","df_parquet = spark.read.parquet(parquet_output_path)\n","\n","# Show the saved data\n","df_parquet.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L7hrMlriFTjy","executionInfo":{"status":"ok","timestamp":1725521501159,"user_tz":-330,"elapsed":2872,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"c245806c-371d-4337-cf09-6f8c44fec2fc"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+------+------+-----------------+\n","| name|age|gender|salary|salary_with_bonus|\n","+-----+---+------+------+-----------------+\n","| John| 28|  Male| 60000|          66000.0|\n","| Jane| 32|Female| 72000|          79200.0|\n","| Mike| 45|  Male| 84000|          92400.0|\n","|Emily| 23|Female| 52000|          57200.0|\n","| Alex| 36|  Male| 67000|          73700.0|\n","+-----+---+------+------+-----------------+\n","\n"]}]}]}