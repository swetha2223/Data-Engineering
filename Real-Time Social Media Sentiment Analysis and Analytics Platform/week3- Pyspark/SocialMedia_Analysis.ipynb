{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mIJ4vS8WpxNl",
        "T18ZW6mqy4Sg",
        "_ezjiytyz2QS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In8-Xe0Rozn2",
        "outputId": "cf6694aa-5b98-4132-e05a-a21d9537d97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=7c7f18a21795410a065b4461ef8f136f23592bf03c19cdddfcfc496592184201\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DataIngesttion\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "csv_file_path = \"/content/sample_data/post_fact.csv\"\n",
        "df_post = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n",
        "df_post.show(10)\n",
        "\n",
        "csv_file_path = \"/content/sample_data/user_details.csv\"\n",
        "df_user = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n",
        "df_user.show(10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xj3A0Hio8xn",
        "outputId": "6ab12bd4-56c0-4e4e-fe1f-aeffe64481df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+--------------------+----------------+---------------+---------+\n",
            "|post_id|user_id|           post_text|       post_date|sentiment_score| platform|\n",
            "+-------+-------+--------------------+----------------+---------------+---------+\n",
            "|      1|     44|Enjoyed a relaxin...|10-11-2024 05:43|            0.8|     NULL|\n",
            "|      2|     30|The food was amaz...|06-12-2025 09:00|           -0.5|     NULL|\n",
            "|      3|     16|Enjoyed a nice da...|10-08-2025 10:13|            0.5| Facebook|\n",
            "|      4|      5|Had an okay day, ...|31-08-2025 16:08|            0.1| Facebook|\n",
            "|      5|     34|The weather is pe...|15-10-2024 15:55|            0.3| Facebook|\n",
            "|      6|     35|Excited about the...|13-07-2024 03:33|            0.2|     NULL|\n",
            "|      7|     34|The weather is pe...|13-08-2024 14:47|           -0.2|     NULL|\n",
            "|      8|     24|Enjoyed a relaxin...|15-09-2024 13:03|            0.4|Instagram|\n",
            "|      9|     26|Excited about the...|29-03-2025 15:28|           -0.0|Instagram|\n",
            "|     10|     34|Had an awesome wo...|01-07-2024 13:54|            0.8|Instagram|\n",
            "+-------+-------+--------------------+----------------+---------------+---------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+-------+---------+---------+-----------+\n",
            "|user_id|user_name| location|date_joined|\n",
            "+-------+---------+---------+-----------+\n",
            "|      1|     NULL|     NULL| 15-01-2024|\n",
            "|      2|     NULL|Bangalore| 05-02-2024|\n",
            "|      3|    Rahul|     NULL| 10-03-2024|\n",
            "|      4|    Sneha|  Chennai| 22-04-2024|\n",
            "|      5|     Ravi|Hyderabad| 11-05-2024|\n",
            "|      6|     NULL|     NULL| 01-06-2024|\n",
            "|      7|    Sunil|     NULL| 15-06-2024|\n",
            "|      8|     NULL|     NULL| 05-07-2024|\n",
            "|      9|     NULL|     NULL| 20-07-2024|\n",
            "|     10|     NULL|     NULL| 10-08-2024|\n",
            "+-------+---------+---------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "mIJ4vS8WpxNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "user field data is processed"
      ],
      "metadata": {
        "id": "m8AKZPK0rKfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, trim, col\n",
        "\n",
        "df_user = df_user.withColumn('user_name', when(trim(col('user_name')) == '', None).otherwise(trim(col('user_name'))))\n",
        "df_user = df_user.withColumn('location', when(trim(col('location')) == '', None).otherwise(trim(col('location'))))\n",
        "\n",
        "df_user = df_user.fillna({'user_name': 'Anonymous_user', 'location': 'Unknown'})\n",
        "\n",
        "\n",
        "print(\"After changing the null value in user details\")\n",
        "df_user.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIr_p9JkpneN",
        "outputId": "41f6abae-627f-4bc0-bf73-2a9315a194d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After changing the null value in user details\n",
            "+-------+--------------+---------+-----------+\n",
            "|user_id|     user_name| location|date_joined|\n",
            "+-------+--------------+---------+-----------+\n",
            "|      1|Anonymous_user|  Unknown| 15-01-2024|\n",
            "|      2|Anonymous_user|Bangalore| 05-02-2024|\n",
            "|      3|         Rahul|  Unknown| 10-03-2024|\n",
            "|      4|         Sneha|  Chennai| 22-04-2024|\n",
            "|      5|          Ravi|Hyderabad| 11-05-2024|\n",
            "|      6|Anonymous_user|  Unknown| 01-06-2024|\n",
            "|      7|         Sunil|  Unknown| 15-06-2024|\n",
            "|      8|Anonymous_user|  Unknown| 05-07-2024|\n",
            "|      9|Anonymous_user|  Unknown| 20-07-2024|\n",
            "|     10|Anonymous_user|  Unknown| 10-08-2024|\n",
            "+-------+--------------+---------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post field data is processed"
      ],
      "metadata": {
        "id": "KGv6CW-drPf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_post = df_post.withColumn('post_text', when(trim(col('post_text')) == '', None).otherwise(trim(col('post_text'))))\n",
        "df_post = df_post.withColumn('platform', when(trim(col('platform')) == '', None).otherwise(trim(col('platform'))))\n",
        "\n",
        "df_post = df_post.fillna({'post_text': 'No content', 'platform': 'Diff_source'})\n",
        "\n",
        "print(\"After changing the null value in post details\")\n",
        "df_post.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhBeJ6wDrJBf",
        "outputId": "d1b2a023-f06a-4131-eeed-ae1ffec3b1ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After changing the null value in post details\n",
            "+-------+-------+--------------------+----------------+---------------+-----------+\n",
            "|post_id|user_id|           post_text|       post_date|sentiment_score|   platform|\n",
            "+-------+-------+--------------------+----------------+---------------+-----------+\n",
            "|      1|     44|Enjoyed a relaxin...|10-11-2024 05:43|            0.8|Diff_source|\n",
            "|      2|     30|The food was amaz...|06-12-2025 09:00|           -0.5|Diff_source|\n",
            "|      3|     16|Enjoyed a nice da...|10-08-2025 10:13|            0.5|   Facebook|\n",
            "|      4|      5|Had an okay day, ...|31-08-2025 16:08|            0.1|   Facebook|\n",
            "|      5|     34|The weather is pe...|15-10-2024 15:55|            0.3|   Facebook|\n",
            "|      6|     35|Excited about the...|13-07-2024 03:33|            0.2|Diff_source|\n",
            "|      7|     34|The weather is pe...|13-08-2024 14:47|           -0.2|Diff_source|\n",
            "|      8|     24|Enjoyed a relaxin...|15-09-2024 13:03|            0.4|  Instagram|\n",
            "|      9|     26|Excited about the...|29-03-2025 15:28|           -0.0|  Instagram|\n",
            "|     10|     34|Had an awesome wo...|01-07-2024 13:54|            0.8|  Instagram|\n",
            "+-------+-------+--------------------+----------------+---------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "droping the post text which has no content in it."
      ],
      "metadata": {
        "id": "1ypY5-cWsTaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "df_post = df_post.filter(col('post_text') != 'No content')\n",
        "\n",
        "print(\"Data after permanently dropping rows where post_text is 'No content':\")\n",
        "df_post.show(15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUHp_4rjrhHR",
        "outputId": "3dcb0856-65fe-4a46-e4b4-09974e380f62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data after permanently dropping rows where post_text is 'No content':\n",
            "+-------+-------+--------------------+----------------+---------------+-----------+\n",
            "|post_id|user_id|           post_text|       post_date|sentiment_score|   platform|\n",
            "+-------+-------+--------------------+----------------+---------------+-----------+\n",
            "|      1|     44|Enjoyed a relaxin...|10-11-2024 05:43|            0.8|Diff_source|\n",
            "|      2|     30|The food was amaz...|06-12-2025 09:00|           -0.5|Diff_source|\n",
            "|      3|     16|Enjoyed a nice da...|10-08-2025 10:13|            0.5|   Facebook|\n",
            "|      4|      5|Had an okay day, ...|31-08-2025 16:08|            0.1|   Facebook|\n",
            "|      5|     34|The weather is pe...|15-10-2024 15:55|            0.3|   Facebook|\n",
            "|      6|     35|Excited about the...|13-07-2024 03:33|            0.2|Diff_source|\n",
            "|      7|     34|The weather is pe...|13-08-2024 14:47|           -0.2|Diff_source|\n",
            "|      8|     24|Enjoyed a relaxin...|15-09-2024 13:03|            0.4|  Instagram|\n",
            "|      9|     26|Excited about the...|29-03-2025 15:28|           -0.0|  Instagram|\n",
            "|     10|     34|Had an awesome wo...|01-07-2024 13:54|            0.8|  Instagram|\n",
            "|     11|     26|Enjoyed a nice da...|22-06-2024 16:53|           -0.7|  Instagram|\n",
            "|     12|     32| Had a peaceful day.|23-06-2024 08:40|            0.5|    Twitter|\n",
            "|     13|     41| Had a peaceful day.|31-07-2024 12:50|           -0.6|  Instagram|\n",
            "|     14|     24|Excited about the...|27-09-2024 12:25|            0.0|   Facebook|\n",
            "|     15|     29|Traffic was terri...|11-03-2025 14:25|            0.5|    Twitter|\n",
            "+-------+-------+--------------------+----------------+---------------+-----------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging the Data"
      ],
      "metadata": {
        "id": "YTapjz1eslHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_merged = df_user.join(df_post, on='user_id', how='inner')\n",
        "\n",
        "\n",
        "print(\"Merged DataFrame:\")\n",
        "df_merged.show(5)\n",
        "\n",
        "df_merged.write.csv('merged_data.csv', header=True, mode='overwrite')\n",
        "\n",
        "print(\"Merged CSV file 'merged_data.csv' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPjXVOPItFK4",
        "outputId": "1174394c-aeab-48e3-c317-5fcdb7d1edea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged DataFrame:\n",
            "+-------+--------------+---------+-----------+-------+--------------------+----------------+---------------+-----------+\n",
            "|user_id|     user_name| location|date_joined|post_id|           post_text|       post_date|sentiment_score|   platform|\n",
            "+-------+--------------+---------+-----------+-------+--------------------+----------------+---------------+-----------+\n",
            "|     44|           Jay|  Chennai| 05-09-2025|      1|Enjoyed a relaxin...|10-11-2024 05:43|            0.8|Diff_source|\n",
            "|     30|         Pooja|   Mumbai| 15-04-2025|      2|The food was amaz...|06-12-2025 09:00|           -0.5|Diff_source|\n",
            "|     16|         Akash|  Unknown| 05-11-2024|      3|Enjoyed a nice da...|10-08-2025 10:13|            0.5|   Facebook|\n",
            "|      5|          Ravi|Hyderabad| 11-05-2024|      4|Had an okay day, ...|31-08-2025 16:08|            0.1|   Facebook|\n",
            "|     34|Anonymous_user|  Unknown| 25-05-2025|      5|The weather is pe...|15-10-2024 15:55|            0.3|   Facebook|\n",
            "+-------+--------------+---------+-----------+-------+--------------------+----------------+---------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Merged CSV file 'merged_data.csv' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.coalesce(1).write.csv('merged_data.csv', header=True, mode='overwrite')\n"
      ],
      "metadata": {
        "id": "XnNYw1F5tKyr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting the Post by platform"
      ],
      "metadata": {
        "id": "XUP3xNcHxGvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "post_count_by_platform = df_merged.groupBy('platform').count()\n",
        "post_count_by_platform = post_count_by_platform.withColumnRenamed('count', 'post_count')\n",
        "print(\"Number of posts by platform:\")\n",
        "post_count_by_platform.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPu8N7UGxJ_H",
        "outputId": "a38ede32-a8b9-4079-e3ca-ef62a781d36d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of posts by platform:\n",
            "+-----------+----------+\n",
            "|   platform|post_count|\n",
            "+-----------+----------+\n",
            "|Diff_source|      2428|\n",
            "|  Instagram|      2550|\n",
            "|    Twitter|      2534|\n",
            "|   Facebook|      2488|\n",
            "+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter Neutral  Sentiment Posts"
      ],
      "metadata": {
        "id": "EaW5rM7nxSaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "neutral_posts = df_merged.filter(df_merged['sentiment_score'] == 0)\n",
        "print(\"Neutral sentiment posts:\")\n",
        "neutral_posts.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l01a9WPQxgEu",
        "outputId": "e2fdbe40-9493-4c64-95af-0b12c374a23d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral sentiment posts:\n",
            "+-------+--------------+---------+-----------+-------+--------------------+----------------+---------------+-----------+\n",
            "|user_id|     user_name| location|date_joined|post_id|           post_text|       post_date|sentiment_score|   platform|\n",
            "+-------+--------------+---------+-----------+-------+--------------------+----------------+---------------+-----------+\n",
            "|     44|           Jay|  Chennai| 05-09-2025|      1|Enjoyed a relaxin...|10-11-2024 05:43|            0.8|Diff_source|\n",
            "|     30|         Pooja|   Mumbai| 15-04-2025|      2|The food was amaz...|06-12-2025 09:00|           -0.5|Diff_source|\n",
            "|     16|         Akash|  Unknown| 05-11-2024|      3|Enjoyed a nice da...|10-08-2025 10:13|            0.5|   Facebook|\n",
            "|      5|          Ravi|Hyderabad| 11-05-2024|      4|Had an okay day, ...|31-08-2025 16:08|            0.1|   Facebook|\n",
            "|     34|Anonymous_user|  Unknown| 25-05-2025|      5|The weather is pe...|15-10-2024 15:55|            0.3|   Facebook|\n",
            "|     35|        Vishal|  Unknown| 05-06-2025|      6|Excited about the...|13-07-2024 03:33|            0.2|Diff_source|\n",
            "|     34|Anonymous_user|  Unknown| 25-05-2025|      7|The weather is pe...|13-08-2024 14:47|           -0.2|Diff_source|\n",
            "|     24|Anonymous_user|  Unknown| 15-02-2025|      8|Enjoyed a relaxin...|15-09-2024 13:03|            0.4|  Instagram|\n",
            "|     26|         Divya|  Unknown| 05-03-2025|      9|Excited about the...|29-03-2025 15:28|           -0.0|  Instagram|\n",
            "|     34|Anonymous_user|  Unknown| 25-05-2025|     10|Had an awesome wo...|01-07-2024 13:54|            0.8|  Instagram|\n",
            "|     26|         Divya|  Unknown| 05-03-2025|     11|Enjoyed a nice da...|22-06-2024 16:53|           -0.7|  Instagram|\n",
            "|     32|        Snehal|Hyderabad| 05-05-2025|     12| Had a peaceful day.|23-06-2024 08:40|            0.5|    Twitter|\n",
            "|     41|       Abhinav|Bangalore| 05-08-2025|     13| Had a peaceful day.|31-07-2024 12:50|           -0.6|  Instagram|\n",
            "|     24|Anonymous_user|  Unknown| 15-02-2025|     14|Excited about the...|27-09-2024 12:25|            0.0|   Facebook|\n",
            "|     29|       Karthik|  Unknown| 05-04-2025|     15|Traffic was terri...|11-03-2025 14:25|            0.5|    Twitter|\n",
            "|      6|Anonymous_user|  Unknown| 01-06-2024|     16|Excited for the n...|06-08-2024 17:17|            0.5|Diff_source|\n",
            "|     10|Anonymous_user|  Unknown| 10-08-2024|     17|The commute was e...|06-11-2024 12:53|            0.8|   Facebook|\n",
            "|     12|         Arjun|  Unknown| 05-09-2024|     20|Had an awesome wo...|22-10-2024 15:40|           -0.9|   Facebook|\n",
            "|     17|Anonymous_user|  Chennai| 20-11-2024|     21|Not feeling well ...|30-08-2025 14:11|           -0.6|   Facebook|\n",
            "|     41|       Abhinav|Bangalore| 05-08-2025|     22|Traffic was terri...|01-12-2024 07:37|            0.0|    Twitter|\n",
            "+-------+--------------+---------+-----------+-------+--------------------+----------------+---------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative post count by pplatform"
      ],
      "metadata": {
        "id": "9YG3z8h4yA53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "negative_posts = df_merged.filter(df_merged['sentiment_score'] < 0)\n",
        "negative_post_count_by_platform = negative_posts.groupBy('platform').count()\n",
        "\n",
        "negative_post_count_by_platform = negative_post_count_by_platform.withColumnRenamed('count', 'negative_post_count')\n",
        "print(\"Number of negative sentiment posts by platform:\")\n",
        "negative_post_count_by_platform.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maEDubMax8I7",
        "outputId": "852073cf-bd14-4e67-8c60-6e69f829c735"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of negative sentiment posts by platform:\n",
            "+-----------+-------------------+\n",
            "|   platform|negative_post_count|\n",
            "+-----------+-------------------+\n",
            "|Diff_source|                 70|\n",
            "|  Instagram|                 58|\n",
            "|    Twitter|                 86|\n",
            "|   Facebook|                 67|\n",
            "+-----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Real-Time Sentiment Analysis"
      ],
      "metadata": {
        "id": "T18ZW6mqy4Sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RealTimeSentimentAnalysis\").getOrCreate()\n",
        "\n",
        "\n",
        "csv_file_path = \"/content/social media.csv\"\n",
        "df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n",
        "\n",
        "# Clean and handle missing values\n",
        "df_clean = df_csv.dropna(subset=['post_content', 'sentiment_score_id'])\n",
        "df_filled = df_clean.fillna({'followers_count': 0, 'sentiment_type': 'unknown'})\n",
        "\n",
        "# Download and initialize VADER sentiment analyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define UDF to compute sentiment\n",
        "def compute_sentiment(post_content):\n",
        "    score = sid.polarity_scores(post_content)\n",
        "    if score['compound'] >= 0.05:\n",
        "        return 'positive'\n",
        "    elif score['compound'] <= -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Register UDF\n",
        "sentiment_udf = udf(compute_sentiment, StringType())\n",
        "\n",
        "# Apply UDF to compute sentiment and create a new 'sentiment' column\n",
        "df_with_sentiment = df_filled.withColumn(\"sentiment\", sentiment_udf(df_filled[\"post_content\"]))\n",
        "df_final = df_with_sentiment.select(\"post_id\", \"post_content\", \"platform\", \"sentiment\")\n",
        "df_final.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF3bPCzFz3JA",
        "outputId": "90920913-a082-4ac8-8543-f9f44ec657d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+---------+\n",
            "|post_id|post_content|  platform|sentiment|\n",
            "+-------+------------+----------+---------+\n",
            "|    101|  2022-01-15|2024-09-18|  neutral|\n",
            "|    102|  2020-06-25|2024-09-19|  neutral|\n",
            "|    103|  2021-05-10|2024-09-20|  neutral|\n",
            "|    104|  2019-11-20|2024-09-18|  neutral|\n",
            "|    105|  2023-03-05|2024-09-19|  neutral|\n",
            "|    106|  2018-07-14|2024-09-18|  neutral|\n",
            "|    107|  2021-09-30|2024-09-20|  neutral|\n",
            "|    108|  2020-12-12|2024-09-19|  neutral|\n",
            "|    109|  2022-06-01|2024-09-18|  neutral|\n",
            "|    110|  2020-04-18|2024-09-20|  neutral|\n",
            "+-------+------------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Real-Time Trend Analysis"
      ],
      "metadata": {
        "id": "_ezjiytyz2QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, to_date, count\n",
        "from pyspark.sql.types import StringType\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RealTimeSentimentTrend\").getOrCreate()\n",
        "\n",
        "csv_file_path = \"/content/social media.csv\"\n",
        "df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def compute_sentiment(post_content):\n",
        "    score = sid.polarity_scores(post_content)\n",
        "    return 'positive' if score['compound'] >= 0.05 else 'negative' if score['compound'] <= -0.05 else 'neutral'\n",
        "\n",
        "sentiment_udf = udf(compute_sentiment, StringType())\n",
        "\n",
        "df_with_sentiment = df_csv.withColumn(\"sentiment\", sentiment_udf(df_csv[\"post_content\"]))\n",
        "\n",
        "# Add 'date' column based on 'post_date'\n",
        "df_with_sentiment = df_with_sentiment.withColumn(\"date\", to_date(df_with_sentiment[\"post_date\"]))\n",
        "\n",
        "# Group by date and sentiment type to calculate sentiment trends\n",
        "df_trend = df_with_sentiment.groupBy(\"date\", \"sentiment\").agg(count(\"post_id\").alias(\"sentiment_count\"))\n",
        "\n",
        "# Show the trends\n",
        "df_trend.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL76XWNJy3-G",
        "outputId": "935abe5a-3dd4-46b4-ab28-a3041b58e7ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+---------------+\n",
            "|date|sentiment|sentiment_count|\n",
            "+----+---------+---------------+\n",
            "|NULL|  neutral|             10|\n",
            "+----+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}