{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN7vo2-RzXfp",
        "outputId": "5cce5bca-7a19-49b4-8748-0b5e969da1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.43)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=c238664675db8f9105d19214e8d2696c637724876f60383272ad4efb37ae57b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n",
            "Collecting delta-spark\n",
            "  Downloading delta_spark-3.2.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyspark<3.6.0,>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from delta-spark) (3.5.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from delta-spark) (8.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (3.20.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark<3.6.0,>=3.5.3->delta-spark) (0.10.9.7)\n",
            "Downloading delta_spark-3.2.1-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: delta-spark\n",
            "Successfully installed delta-spark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install pyspark\n",
        "!pip install delta-spark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "bWf068q7z-xf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GETTING DATA OF REQUIRED COMPANY FROM THE YAHOO API**\n",
        "\n",
        "DATA GATHERING STEP"
      ],
      "metadata": {
        "id": "GlKR9XVJ7uxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def getData(ticker, filename='combined_stock_data.csv'):\n",
        "    # Download stock data for the given ticker symbol\n",
        "    stock_data = yf.download(ticker, start='2023-01-01', end='2023-09-27')\n",
        "\n",
        "    # Rename columns to the desired format\n",
        "    stock_data.rename(columns={\n",
        "        'High': 'High',\n",
        "        'Low': 'Low',\n",
        "        'Open': 'Open',\n",
        "        'Close': 'Close',\n",
        "        'Adj Close': 'Adj Close',\n",
        "        'Volume': 'Volume'\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Reset index to get the 'Date' column as a separate column\n",
        "    stock_data.reset_index(inplace=True)\n",
        "\n",
        "    # Add a 'Ticker' column to identify which stock the data belongs to\n",
        "    stock_data['ticker_symbol'] = ticker\n",
        "\n",
        "    # Select only the relevant columns\n",
        "    formatted_data = stock_data[['Date', 'ticker_symbol', 'High', 'Volume', 'Low', 'Open', 'Close', 'Adj Close']]\n",
        "\n",
        "    # If the file already exists, append data; otherwise, create the file\n",
        "    if os.path.exists(filename):\n",
        "        # Append mode\n",
        "        formatted_data.to_csv(filename, mode='a', header=False, index=False)\n",
        "    else:\n",
        "        # Write mode with header\n",
        "        formatted_data.to_csv(filename, index=False)\n",
        "\n",
        "    print(f\"Data for {ticker} appended to {filename}\")\n",
        "\n",
        "# Example Usage: Append data for multiple tickers\n",
        "getData('WIT')     # For Wipro's stock data\n",
        "getData('INFY')   # For Google's stock data\n",
        "getData('GOOGL')\n",
        "getData('MSFT')   # For Microsoft's stock data\n",
        "getData('ACN')\n",
        "getData('CTSH')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGTbr9Oz6xto",
        "outputId": "022c0b32-8dbd-408f-b1e5-e5f4c8b87500"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for WIT appended to combined_stock_data.csv\n",
            "Data for INFY appended to combined_stock_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for GOOGL appended to combined_stock_data.csv\n",
            "Data for MSFT appended to combined_stock_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for ACN appended to combined_stock_data.csv\n",
            "Data for CTSH appended to combined_stock_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df2):\n",
        "    ticker_list={\n",
        "        \"WIT\":1,\n",
        "        \"INFY\":2,\n",
        "        \"GOOGL\":3,\n",
        "        \"MSFT\":4,\n",
        "        \"ACN\":5,\n",
        "        \"CTSH\":6\n",
        "    }\n",
        "    # replace missing values with NULL\n",
        "    df2 = df2.replace(r'/^s*$', np.nan, regex=True)\n",
        "\n",
        "    # count number of NULLS in each column\n",
        "    # print(df2.isna().sum(axis=0))\n",
        "\n",
        "    # Now find rows which are having 3 or more than 3 nulls\n",
        "\n",
        "    #print((df2.isna().sum(axis=1) >= 3).sum())\n",
        "    k1 = df2[df2.isna().sum(axis=1)>= 3]\n",
        "    k1 = k1.index.to_list()\n",
        "    for x in k1:\n",
        "        df2 = df2.drop(x)\n",
        "\n",
        "    # checking whether the data is dropped\n",
        "    #print((df2.isna().sum(axis=1) >= 3).sum())\n",
        "\n",
        "    # Finding number of rows with NULL values\n",
        "    #print(df2[\"Volume\"].isna().sum())\n",
        "    # Dropping the rows\n",
        "    x = df2[df2[\"Volume\"].isna()]\n",
        "    l = x.index.to_list()\n",
        "    for x in l:\n",
        "        df2 = df2.drop(x)\n",
        "\n",
        "       # Checking the volume column\n",
        "    #print(df2[\"Volume\"].isna().sum())\n",
        "\n",
        "    # filling the null values with corresponding means\n",
        "    df2[\"Low\"] = df2[\"Low\"].fillna(df2[\"Low\"].mean())\n",
        "    df2[\"High\"] = df2[\"High\"].fillna(df2[\"High\"].mean())\n",
        "    df2[\"Open\"] = df2[\"Open\"].fillna(df2[\"Open\"].mean())\n",
        "    df2[\"Close\"] = df2[\"Close\"].fillna(df2[\"Close\"].mean())\n",
        "    df2[\"Adj Close\"] = df2[\"Adj Close\"].fillna(df2[\"Adj Close\"].mean())\n",
        "\n",
        "    # Data Cleaning part is completed now we should transform the data into the required format\n",
        "    ''' The table format we have in the table is\n",
        "    Stock_id,company_id,Stock_prize,Trading_volume,RSI,MarketCap,Date\n",
        "    '''\n",
        "    df2[\"moving_avg\"]=df2[\"Close\"].rolling(window=14).mean()\n",
        "    #df2.iloc[0:13,5]=df2.iloc[14,5]\n",
        "\n",
        "    window_length=14\n",
        "    relative_close_diff=df2[\"Close\"].diff()\n",
        "\n",
        "    gain=relative_close_diff.where(relative_close_diff>0,0)\n",
        "    loss=-relative_close_diff.where(relative_close_diff<0,0)\n",
        "\n",
        "    avg_gain=gain.rolling(window_length,min_periods=1).mean()\n",
        "    avg_loss =loss.rolling(window_length, min_periods=1).mean()\n",
        "\n",
        "    rs=avg_gain/avg_loss\n",
        "\n",
        "    df2[\"RSI\"]=100-(100/(1+rs))\n",
        "\n",
        "    df=pd.DataFrame()\n",
        "    df[\"Stock_id\"]=[x for x in range(1,len(df2))]\n",
        "    df['Company_id'] = df2['ticker_symbol'].map(ticker_list)\n",
        "    df[\"Stock_Price\"]=(df2[\"Open\"]+df2[\"Close\"]+df2[\"Low\"]+df2[\"High\"])/4\n",
        "    df[\"Trading_Volume\"]=df2[\"Volume\"]\n",
        "    df['Moving_Average']=df2['moving_avg']\n",
        "    df[\"Market_Cap\"]=df2[\"Adj Close\"]\n",
        "    df[\"RSI\"]=df2[\"RSI\"]\n",
        "    df[\"Record_Time\"]=df2[\"Date\"]\n",
        "    df.dropna(inplace=True)\n",
        "    df.iloc[0:2,4]=df.iloc[2,4]\n",
        "\n",
        "    # Checking Whether The Null Values are filled\n",
        "    #print(df2.isna().sum())\n",
        "    #print(\"**********************************************************************************\")\n",
        "    return df\n",
        "df1=pd.read_csv(\"combined_stock_data.csv\")\n",
        "df1=preprocess(df1)\n",
        "print(df1)\n",
        "df1.to_csv(\"cleaned_data.csv\",index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4OpVQ75-nDx",
        "outputId": "274d2e69-fb14-46d1-d768-56d5c4a77547"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Stock_id  Company_id  Stock_Price  Trading_Volume  Moving_Average  \\\n",
            "13          14           1     4.992500         3438800        4.851429   \n",
            "14          15           1     4.970000         4061100        4.851429   \n",
            "15          16           1     4.897500         3277000        4.851429   \n",
            "16          17           1     4.925000         4023400        4.876429   \n",
            "17          18           1     4.895000         1837200        4.893571   \n",
            "...        ...         ...          ...             ...             ...   \n",
            "1098      1099           6    69.795000         5046500       70.950000   \n",
            "1099      1100           6    70.137503         3550100       70.808571   \n",
            "1100      1101           6    69.327499         2585000       70.637143   \n",
            "1101      1102           6    69.469999         2048400       70.485714   \n",
            "1102      1103           6    69.557501         3463800       70.397143   \n",
            "\n",
            "      Market_Cap        RSI Record_Time  \n",
            "13      4.967611  70.588206  2023-01-23  \n",
            "14      4.969607  69.565214  2023-01-24  \n",
            "15      4.909732  65.753426  2023-01-25  \n",
            "16      4.939670  76.119411  2023-01-26  \n",
            "17      4.889774  68.181854  2023-01-27  \n",
            "...          ...        ...         ...  \n",
            "1098   68.959373  35.729851  2023-09-19  \n",
            "1099   68.388741  30.511919  2023-09-20  \n",
            "1100   68.093575  27.186373  2023-09-21  \n",
            "1101   68.487122  30.866457  2023-09-22  \n",
            "1102   68.605186  37.347004  2023-09-25  \n",
            "\n",
            "[1090 rows x 8 columns]\n"
          ]
        }
      ]
    }
  ]
}