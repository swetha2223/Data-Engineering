{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2edbbaf0-6bda-4a40-99df-303ef7eda34c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eda31b29-1ec0-4c67-90df-c62a89980f1d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "1. Create Delta Tables Using 3 Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b2a5c82-9672-4283-9b76-8b916ce671ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dbutils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Move the file from Workspace to DBFS\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdbutils\u001b[49m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mcp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile:/Workspace/Shared/Sales1_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbfs:/FileStore/Sales1_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Load CSV data into a DataFrame\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df_sales \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbfs:/FileStore/Sales1_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dbutils' is not defined"
     ]
    }
   ],
   "source": [
    "#Move the file from Workspace to DBFS\n",
    "dbutils.fs.cp(\"file:/Workspace/Shared/Sales1_data.csv\", \"dbfs:/FileStore/Sales1_data.csv\")\n",
    "#Load CSV data into a DataFrame\n",
    "df_sales = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/Sales1_data.csv\")\n",
    "#Write DataFrame to Delta format\n",
    "df_sales.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/sales1_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86cc7288-03e4-48c6-93dd-23d0b0fc7f72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Define schema for customer_data.json file\n",
    "schema = StructType([ \n",
    "                   StructField(\"CustomerID\", StringType(), True), \n",
    "                   StructField(\"CustomerName\", StringType(), True), \n",
    "                   StructField(\"Region\", StringType(), True), \n",
    "                   StructField(\"SignupDate\", StringType(), True)  # or DateType if dates are in valid format\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3e9d946-a001-4426-a805-6fe54191a9a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the file from Workspace to DBFS\n",
    "dbutils.fs.cp(\"file:/Workspace/Shared/customer_data.json\", \"dbfs:/FileStore/customer_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7683a626-6fd8-4c80-aeed-2e3dd89bfacb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------+----------+\n",
      "|CustomerID| CustomerName|Region|SignupDate|\n",
      "+----------+-------------+------+----------+\n",
      "|      C001|     John Doe| North|2022-07-01|\n",
      "|      C002|   Jane Smith| South|2023-02-15|\n",
      "|      C003|Emily Johnson|  East|2021-11-20|\n",
      "|      C004|Michael Brown|  West|2022-12-05|\n",
      "|      C005|  Linda Davis| North|2023-03-10|\n",
      "+----------+-------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_product=spark.read.format(\"json\").schema(schema).load(\"dbfs:/FileStore/customer_data.json\") \n",
    "df_product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ba96db9-6dd9-4d61-8ca1-3d760fdc9c14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_product.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/customer_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7352602f-dfe3-49b7-b3be-cae5012c887f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "sample_data = [(\"John\", 30), (\"Jane\", 25), (\"Sam\", 35)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "sample_df = spark.createDataFrame(sample_data, columns)\n",
    "\n",
    "# Write the DataFrame as a Parquet file\n",
    "sample_df.write.mode(\"overwrite\").parquet(\"/FileStore/sample_parquet_file.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c59972f-99ad-4760-9484-f678f64e4a02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the Parquet file\n",
    "parquet_df = spark.read.parquet(\"/FileStore/sample_parquet_file.parquet\")\n",
    "\n",
    "# Convert the Parquet file to a Delta Table\n",
    "parquet_df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/sample_parquet_to_delta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0aba6075-1252-4a31-a44f-13f81812cc5b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c1ac685-32df-433c-ab08-d8c8a3d4a37b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/new_sales_data.csv\", \"dbfs:/FileStore/new_sales_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bf6103d-94b2-48cd-8987-20888082f8e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_new_sales = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/FileStore/new_sales_data.csv\")\n",
    "df_new_sales.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/new_sales_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2ebe14c-c29e-4671-b506-fe60865e2f17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sales = spark.read.format(\"delta\").load(\"/delta/sales1_data\")\n",
    "df_new_sales = spark.read.format(\"delta\").load(\"/delta/new_sales_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eade2715-c756-44b9-baa9-2525cfb1fb0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create temporary views for SQL operations with corrected view names\n",
    "df_sales.createOrReplaceTempView(\"delta_sales1\") \n",
    "\n",
    "df_new_sales.createOrReplaceTempView(\"new_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f61a31e0-ff5f-46c1-8808-203a80be056d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    MERGE INTO delta_sales1 AS target\n",
    "    USING new_sales AS source\n",
    "    ON target.OrderID = source.OrderID\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        target.Product = source.Product,\n",
    "        target.CustomerID = source.CustomerID\n",
    "    WHEN NOT MATCHED THEN INSERT \n",
    "    (\n",
    "        OrderID, OrderDate, CustomerID, Product, Quantity, Price\n",
    "    ) VALUES (\n",
    "        source.OrderID, source.OrderDate, source.CustomerID, source.Product,source.Quantity, source.Price\n",
    "    )\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b549184-2377-4421-8e47-7c553414f772",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+--------+--------+-----+\n",
      "|OrderID| OrderDate|CustomerID| Product|Quantity|Price|\n",
      "+-------+----------+----------+--------+--------+-----+\n",
      "|   1001|2024-01-15|      C001|Widget A|      10|25.50|\n",
      "|   1003|2024-01-16|      C001|Widget C|       8|22.50|\n",
      "|   1004|2024-01-17|      C003|Widget A|      15|25.50|\n",
      "|   1005|2024-01-18|      C004|Widget D|       7|30.00|\n",
      "|   1006|2024-01-19|      C002|Widget B|       9|15.75|\n",
      "|   1007|2024-01-20|      C005|Widget C|      12|22.50|\n",
      "|   1008|2024-01-21|      C003|Widget A|      10|25.50|\n",
      "|   1002|2024-01-16|      C002|Widget B|       5|15.75|\n",
      "|   1009|2024-01-22|      C006|Widget E|      14|20.00|\n",
      "|   1010|2024-01-23|      C007|Widget F|       6|35.00|\n",
      "+-------+----------+----------+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM delta_sales1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c59038d-d151-485e-a7cc-6bb310ca4d68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write the employee dataframe to a delta table\n",
    "df_sales.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/sales1_data\")\n",
    "#Register the delta table\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS delta_sales1_table USING DELTA LOCATION '/delta/sales1_data'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2242c2d2-6917-4f2b-b1b9-6a92254f53af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 3 - Optimize Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a7de8e4-302d-4736-9235-2ba2aabd768d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numClusteringTasksPlanned:int,numCompactionTasksPlanned:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numIntermediateNodesCompacted:bigint,totalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\tOPTIMIZE delta_sales1_table ZORDER BY CustomerID\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44908bee-c235-405c-9710-35a061cee9bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ef7cd08-e954-46a4-ac5b-d79574572a17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------+----------------------------------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n",
      "|version|timestamp          |userId          |userName                          |operation|operationParameters                                                                                                                                                                                          |job |notebook          |clusterId           |readVersion|isolationLevel   |isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |userMetadata|engineInfo                                |\n",
      "+-------+-------------------+----------------+----------------------------------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n",
      "|3      |2024-09-13 07:45:29|2543688459691135|azuser2133_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                                                                                                                                                 |NULL|{2276050908675542}|0911-092055-kwchwvew|2          |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 10, numOutputBytes -> 1766}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|2      |2024-09-13 07:38:21|2543688459691135|azuser2133_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}                                                                                                                               |NULL|{2276050908675542}|0911-092055-kwchwvew|1          |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 3216, p25FileSize -> 1766, numDeletionVectorsRemoved -> 1, minFileSize -> 1766, numAddedFiles -> 1, maxFileSize -> 1766, p75FileSize -> 1766, p50FileSize -> 1766, numAddedBytes -> 1766}                                                                                                                                                                                                                                                                                                                                                                                                                                                |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|1      |2024-09-13 07:38:19|2543688459691135|azuser2133_mml.local@techademy.com|MERGE    |{predicate -> [\"(OrderID#7282 = OrderID#7294)\"], matchedPredicates -> [{\"actionType\":\"update\"}], statsOnLoad -> false, notMatchedBySourcePredicates -> [], notMatchedPredicates -> [{\"actionType\":\"insert\"}]}|NULL|{2276050908675542}|0911-092055-kwchwvew|0          |WriteSerializable|false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1495, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 1, numTargetRowsMatchedUpdated -> 1, executionTimeMs -> 1800, materializeSourceTimeMs -> 135, numTargetRowsInserted -> 2, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 747, numTargetRowsUpdated -> 1, numOutputRows -> 3, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 3, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 868}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|0      |2024-09-13 07:18:14|2543688459691135|azuser2133_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                                                                                                                                                 |NULL|{2276050908675542}|0911-092055-kwchwvew|NULL       |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 8, numOutputBytes -> 1721}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "+-------+-------------------+----------------+----------------------------------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Describe history\n",
    "spark.sql(\"DESCRIBE HISTORY delta_sales1_table\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1671f3f3-8cc5-4802-ab52-167f93f935f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m\tVACUUM delta_sales_table RETAIN 168 HOURS\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\tVACUUM delta_sales_table RETAIN 168 HOURS\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8562ae5c-4637-452a-97f5-ff009283ee5b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 5 - Hands on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "748966bd-235f-45da-be1e-af8b762d9d9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+--------+--------+-----+\n",
      "|OrderID| OrderDate|CustomerID| Product|Quantity|Price|\n",
      "+-------+----------+----------+--------+--------+-----+\n",
      "|   1001|2024-01-15|      C001|Widget A|      10|25.50|\n",
      "|   1003|2024-01-16|      C001|Widget C|       8|22.50|\n",
      "|   1004|2024-01-17|      C003|Widget A|      15|25.50|\n",
      "|   1005|2024-01-18|      C004|Widget D|       7|30.00|\n",
      "|   1006|2024-01-19|      C002|Widget B|       9|15.75|\n",
      "|   1007|2024-01-20|      C005|Widget C|      12|22.50|\n",
      "|   1008|2024-01-21|      C003|Widget A|      10|25.50|\n",
      "|   1002|2024-01-16|      C002|Widget B|       5|15.75|\n",
      "|   1009|2024-01-22|      C006|Widget E|      14|20.00|\n",
      "|   1010|2024-01-23|      C007|Widget F|       6|35.00|\n",
      "+-------+----------+----------+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query historical versions using Time Travel\n",
    "historical_df = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"/delta/sales1_data\")\n",
    "historical_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "959312b0-4cb0-4c11-86f1-fcba8ed10547",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Implement Schema Enforcement\n",
    "df_sales.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").save(\"/delta/sales1_data\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sep13-delta_Lake_exercise",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
